## ðŸš€ RAG-Based Chatbot using Streamlit, Langchain, ChromaDB, and OpenAI LLM  

This repository contains the source code for a **Retrieval Augmented Generation (RAG)** based chatbot built using:  
- âœ… **Streamlit** for the user interface (UI).  
- âœ… **Langchain** for building and managing LLM pipelines.  
- âœ… **ChromaDB** as the vector database for storing and retrieving embeddings.  
- âœ… **OpenAI LLM** for generating human-like responses.  

The chatbot allows users to upload documents (PDF, Word, TXT, etc.), processes the data into embeddings, stores them in **ChromaDB**, and enables question-answering based on document content.  

---

## ðŸ“œ Features  

- âœ… **Document Upload**: Allows uploading of PDF, Word, Txt files.  
- âœ… **Data Chunking**: Automatically splits large documents into smaller chunks for embedding creation.  
- âœ… **Embedding Generation**: Using OpenAI LLM.  
- âœ… **Vector Search**: Utilizes **ChromaDB** for fast and accurate document search.  
- âœ… **Chat Interface**: Built-in chat interface using Streamlit.  
- âœ… **Context-Based Answers**: Provides answers based on document content using RAG architecture.  

---

## ðŸ’» Installation  

1. **Clone the repository**  

```shell
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot
```  

2. **Create a virtual environment** (optional but recommended)  

```shell
python3 -m venv venv
source venv/bin/activate   # For MacOS/Linux
venv\Scripts\activate      # For Windows
```  

3. **Install dependencies**  

```shell
pip install -r requirements.txt
```  

4. **Set up your OpenAI API Key**  

In the root directory, create a `.env` file and add your API key:  

```
OPENAI_API_KEY=your_google_openai_api_key
```  

---

## ðŸ“œ Usage  

1. **Run the Streamlit app**  

```shell
streamlit run main.py
```  

2. **Upload a document (PDF, Word, TXT)**  
- Open the URL generated by Streamlit in your browser.  
- Upload any document you wish to query.  

3. **Ask questions**  
- Once uploaded, start asking questions related to the document content.  
- The chatbot will retrieve relevant chunks and provide context-based answers.  

---

## ðŸ“Š Supported File Types  

| File Type | Supported | Notes |
|------------|------------|-------|
| PDF        | âœ… Yes     | Any text-based PDF file. |
| Word (docx) | âœ… Yes     | Microsoft Word documents. |
| TXT        | âœ… Yes     | Any TXT file. |

---

## ðŸ“œ How It Works (RAG Flow)  

### âœ… Step 1: Uploading Files  
- The user uploads a file via the Streamlit UI.  
- The file is stored in the `/data/` directory.  

### âœ… Step 2: Chunking and Embedding  
- The document is split into smaller chunks using Langchain's text splitter.  
- Each chunk is converted to embeddings using **OpenAI LLM embeddings**.  
- The embeddings are then stored in **ChromaDB**.  

### âœ… Step 3: Querying  
- When the user asks a question, the system:  
   1. **Generates an embedding** for the question.  
   2. Searches the most relevant document chunks from ChromaDB.  
   3. Sends the context + question to **OpenAI LLM** for generating the response.  

### âœ… Step 4: Response Generation  
- The OpenAI LLM generates a concise, context-based response using the retrieved chunks.  
- The response is then displayed in the chat window.  
